{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js9t5H_qbOBc"
      },
      "source": [
        "# **Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OwygK9bJK2T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5n5KA6HbVqe"
      },
      "source": [
        "# **Initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10la6phMK2nc"
      },
      "outputs": [],
      "source": [
        "df_fake = pd.read_csv(\"drive/MyDrive/Fake.csv\")\n",
        "df_true = pd.read_csv(\"drive/MyDrive/True.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRIYqeKDK9gW"
      },
      "outputs": [],
      "source": [
        "df_fake.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7IUygzvLBNR"
      },
      "outputs": [],
      "source": [
        "df_true.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9do37BoubaRr"
      },
      "source": [
        "## **Inserting a column \"class\" as target feature**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKl5u0KHLGVg"
      },
      "outputs": [],
      "source": [
        "df_fake[\"class\"] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0pNIjGzLUX-"
      },
      "outputs": [],
      "source": [
        "df_true[\"class\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4AAuxHELY7p"
      },
      "outputs": [],
      "source": [
        "df_fake.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3CraoFBzLeqW"
      },
      "outputs": [],
      "source": [
        "df_fake.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BlTMKZkLtc5"
      },
      "outputs": [],
      "source": [
        "df_true.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYgZxTalLwKX"
      },
      "outputs": [],
      "source": [
        "df_fake_manual_testing = df_fake.tail(10)\n",
        "df_fake = df_fake[:-10]\n",
        "\n",
        "\n",
        "df_true_manual_testing = df_true.tail(10)\n",
        "for i in range(21416,21406,-1):\n",
        "    df_true.drop([i], axis = 0, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PN5C1Mx_NkdF"
      },
      "outputs": [],
      "source": [
        "df_fake.shape, df_true.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL8HXnbobkfW"
      },
      "source": [
        "# **Creating Manual Testing Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPVy2a36NtPP"
      },
      "outputs": [],
      "source": [
        "df_fake_manual_testing[\"class\"] = 0\n",
        "df_true_manual_testing[\"class\"] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyjnYxhQNyUq"
      },
      "outputs": [],
      "source": [
        "df_fake_manual_testing.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K-ro7DaN07G"
      },
      "outputs": [],
      "source": [
        "df_true_manual_testing.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgG4VO1NN5OG"
      },
      "outputs": [],
      "source": [
        "df_manual_testing = pd.concat([df_fake_manual_testing,df_true_manual_testing], axis = 0)\n",
        "df_manual_testing.to_csv(\"manual_testing.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04yCqO5Ubp9-"
      },
      "source": [
        "# **Merging True and False dataframes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvFNZRllOOCu"
      },
      "outputs": [],
      "source": [
        "df_merge = pd.concat([df_fake, df_true], axis =0 )\n",
        "df_merge.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3WKCk2mb2iY"
      },
      "source": [
        "Removing columns which arent needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2rUu9k1OQPh"
      },
      "outputs": [],
      "source": [
        "df_merge.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPOMnTV6OTG1"
      },
      "outputs": [],
      "source": [
        "df = df_merge.drop([\"title\", \"subject\", \"date\"], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shT4PTuqOeV9"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo504lAgb78G"
      },
      "source": [
        "Shuffling Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ay8OLFP_Oh2S"
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTcuIvrmOmxJ"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQl-LF93OpO0"
      },
      "outputs": [],
      "source": [
        "df.reset_index(inplace = True)\n",
        "df.drop([\"index\"], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYOHKSFxOw5e"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM34OYU0b_8i"
      },
      "source": [
        "# **Text Processing Initial Step:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3FKODzGO8Vt"
      },
      "outputs": [],
      "source": [
        "def wordopt(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub(\"\\\\W\",\" \",text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVVukFCIP136"
      },
      "outputs": [],
      "source": [
        "df[\"text\"] = df[\"text\"].apply(wordopt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJx7WMsJcNAt"
      },
      "source": [
        "# **Splitting into Training and Testing [3:1]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIm3Hbj9QB2f"
      },
      "outputs": [],
      "source": [
        "x = df[\"text\"]\n",
        "y = df[\"class\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xvnBmfIQpZA"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu8TLdkeQrTS"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorization = TfidfVectorizer()\n",
        "xv_train = vectorization.fit_transform(x_train)\n",
        "xv_test = vectorization.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e89ymklQ2dg"
      },
      "source": [
        "# **Logistic Regression**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1A6gN_BQwHt"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LR = LogisticRegression()\n",
        "LR.fit(xv_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJfw6hKQRNq-"
      },
      "outputs": [],
      "source": [
        "pred_lr = LR.predict(xv_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbPp7nsvStXd"
      },
      "outputs": [],
      "source": [
        "LR.score(xv_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3VMH2CVS9Sr"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred_lr))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc6yL7EzTJMh"
      },
      "source": [
        "# **Decision Tree Classificiation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF5tfo7zTFzI"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "DT = DecisionTreeClassifier()\n",
        "DT.fit(xv_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKzy38QUTlxa"
      },
      "outputs": [],
      "source": [
        "pred_dt = DT.predict(xv_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPMQ6KFyUFh0"
      },
      "outputs": [],
      "source": [
        "DT.score(xv_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_tTEhnBUP9n"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred_dt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FRR14QXUdZv"
      },
      "source": [
        "# **Gradient Boosting Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAwrgE2OUb4l"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "GBC = GradientBoostingClassifier(random_state=0)\n",
        "GBC.fit(xv_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njANfnUeUr4p"
      },
      "outputs": [],
      "source": [
        "pred_gbc = GBC.predict(xv_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okeZOccZUzlt"
      },
      "outputs": [],
      "source": [
        "GBC.score(xv_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lD-DBzqVU7Va"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred_gbc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrA5ZJ7OVGwb"
      },
      "source": [
        "# **Random Forest Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFJrHajBVhHY"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RFC = RandomForestClassifier(random_state = 0)\n",
        "RFC.fit(xv_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAm8P5deVt72"
      },
      "outputs": [],
      "source": [
        "pred_rfc = RFC.predict(xv_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWst4I8QV0R6"
      },
      "outputs": [],
      "source": [
        "RFC.score(xv_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNwNiSl_V6bc"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, pred_rfc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpvlfUcwX-Nf"
      },
      "source": [
        "# **Manual Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Muz7l20KYCJt"
      },
      "outputs": [],
      "source": [
        "def output_result(n):\n",
        "  if n == 0:\n",
        "    return \"Fake News\"\n",
        "  elif n == 1:\n",
        "    return \"True News\"\n",
        "\n",
        "def manual_testing(news):\n",
        "  testing_news = {\"text\":[news]}\n",
        "  new_def_test = pd.DataFrame(testing_news)\n",
        "  new_def_test[\"text\"] = new_def_test[\"text\"].apply(wordopt)\n",
        "  new_x_test = new_def_test[\"text\"]\n",
        "  new_xv_test = vectorization.transform(new_x_test)\n",
        "  pred_LR = LR.predict(new_xv_test)\n",
        "  pred_DT = DT.predict(new_xv_test)\n",
        "  pred_GBC = GBC.predict(new_xv_test)\n",
        "  pred_RFC = RFC.predict(new_xv_test)\n",
        "\n",
        "  return print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction: {}\".format(output_result(pred_LR[0]),\n",
        "                                                                                                              output_result(pred_DT[0]),\n",
        "                                                                                                              output_result(pred_GBC[0]),\n",
        "                                                                                                              output_result(pred_RFC[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsQTIv7NYct-"
      },
      "outputs": [],
      "source": [
        "\n",
        "news = str(input(\"Enter the news:\"))\n",
        "manual_testing(news)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPNnN7YYH38h"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "# Save models\n",
        "joblib.dump(LR, 'lr_model.pkl')\n",
        "joblib.dump(DT, 'dt_model.pkl')\n",
        "joblib.dump(GBC, 'gbc_model.pkl')\n",
        "joblib.dump(RFC, 'rfc_model.pkl')\n",
        "\n",
        "# Save the vectorizer\n",
        "joblib.dump(vectorization, 'vectorizer.pkl')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summarizer**"
      ],
      "metadata": {
        "id": "ihc6ZXHci9HM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "id": "utSWKZz6jEEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load GloVe embeddings (100 dimensions)\n",
        "glove_vectors = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "id": "B6MpqZxKjd8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')   # Word tokenization\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    sentences = sent_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    sentences = [\n",
        "        [word for word in word_tokenize(sentence) if word not in stop_words]\n",
        "        for sentence in sentences\n",
        "    ]\n",
        "\n",
        "    cleaned_text = \" \".join([\" \".join(sentence) for sentence in sentences])\n",
        "\n",
        "    return sentences, cleaned_text"
      ],
      "metadata": {
        "id": "EwIH-xHxkEF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sentence_vector(sentence, glove_vectors):\n",
        "    word_vectors = [glove_vectors[word] for word in sentence if word in glove_vectors]\n",
        "    if len(word_vectors) == 0:\n",
        "        return np.zeros(glove_vectors.vector_size)#If no GloVe vectors are found for the words, return a zero vector\n",
        "\n",
        "    return np.mean(word_vectors, axis=0)  #Average the word vectors to get the sentence vector\n",
        "\n",
        "sentence_vectors = [sentence_vector(sentence, glove_vectors) for sentence in processed_sentences]\n"
      ],
      "metadata": {
        "id": "tKkYbMIOkYg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "cos_sim_matrix = cosine_similarity(sentence_vectors)\n",
        "sentence_scores = np.sum(cos_sim_matrix, axis=1)"
      ],
      "metadata": {
        "id": "d2aDIXVtk_13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text, glove_vectors, top_n=3):\n",
        "    sentences, _ = preprocess_text(text)\n",
        "    sentence_vectors = [sentence_vector(sentence, glove_vectors) for sentence in sentences]\n",
        "    cos_sim_matrix = cosine_similarity(sentence_vectors)\n",
        "    sentence_scores = np.sum(cos_sim_matrix, axis=1)\n",
        "    top_sentence_indices = sentence_scores.argsort()[-top_n:][::-1]\n",
        "    summary = [sentences[i] for i in top_sentence_indices]\n",
        "    return ' '.join([' '.join(sentence) for sentence in summary])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MEI7K_G1lJ2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def manual_testing_with_summary():\n",
        "    news = input(\"Please enter the news text: \")\n",
        "    testing_news = {\"text\": [news]}\n",
        "    new_def_test = pd.DataFrame(testing_news)\n",
        "    new_def_test[\"text\"] = new_def_test[\"text\"].apply(wordopt)\n",
        "\n",
        "    new_x_test = new_def_test[\"text\"]\n",
        "    new_xv_test = vectorization.transform(new_x_test)\n",
        "\n",
        "    pred_LR = LR.predict(new_xv_test)\n",
        "    pred_DT = DT.predict(new_xv_test)\n",
        "    pred_GBC = GBC.predict(new_xv_test)\n",
        "    pred_RFC = RFC.predict(new_xv_test)\n",
        "\n",
        "    # Generate the summary of the input news\n",
        "    summary = generate_summary(news, glove_vectors, top_n=3)\n",
        "\n",
        "    # Print the predictions from all models\n",
        "    print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction: {}\".format(\n",
        "        output_result(pred_LR[0]),\n",
        "        output_result(pred_DT[0]),\n",
        "        output_result(pred_GBC[0]),\n",
        "        output_result(pred_RFC[0])\n",
        "    ))\n",
        "\n",
        "    # Print the summary of the news\n",
        "    print(\"\\nSummary of the news:\\n\", summary)\n",
        "\n"
      ],
      "metadata": {
        "id": "jLazTQ8NlS2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manual_testing_with_summary()"
      ],
      "metadata": {
        "id": "32QMJVlGsKus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "0MMhHtnzsry1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "def summarize_sentence_bart(sentence: str):\n",
        "\n",
        "    testing_news = {\"text\": [sentence]}\n",
        "    new_def_test = pd.DataFrame(testing_news)\n",
        "\n",
        "    new_def_test[\"text\"] = new_def_test[\"text\"].apply(wordopt)\n",
        "\n",
        "    new_x_test = new_def_test[\"text\"]\n",
        "    new_xv_test = vectorization.transform(new_x_test)\n",
        "\n",
        "    pred_LR = LR.predict(new_xv_test)\n",
        "    pred_DT = DT.predict(new_xv_test)\n",
        "    pred_GBC = GBC.predict(new_xv_test)\n",
        "    pred_RFC = RFC.predict(new_xv_test)\n",
        "\n",
        "    print(\"\\n\\nLR Prediction: {} \\nDT Prediction: {} \\nGBC Prediction: {} \\nRFC Prediction: {}\".format(\n",
        "        output_result(pred_LR[0]),\n",
        "        output_result(pred_DT[0]),\n",
        "        output_result(pred_GBC[0]),\n",
        "        output_result(pred_RFC[0])\n",
        "    ))\n",
        "\n",
        "    if(output_result(pred_GBC[0]) == \"True News\"):\n",
        "      if len(sentence.split()) < 5:\n",
        "        return sentence  # Return the original sentence if it's too short to summarize\n",
        "\n",
        "      summary = summarizer(sentence, max_length=50, min_length=25, do_sample=False)\n",
        "\n",
        "      return summary[0]['summary_text']"
      ],
      "metadata": {
        "id": "jCm3-x3Qszl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sentence = input(\"Enter Sentence: \")\n",
        "print(summarize_sentence_bart(input_sentence))"
      ],
      "metadata": {
        "id": "eSegnZtyzozO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Js9t5H_qbOBc",
        "v5n5KA6HbVqe",
        "9do37BoubaRr",
        "JL8HXnbobkfW",
        "04yCqO5Ubp9-",
        "VM34OYU0b_8i",
        "CJx7WMsJcNAt",
        "9e89ymklQ2dg",
        "hc6yL7EzTJMh",
        "2FRR14QXUdZv",
        "IrA5ZJ7OVGwb",
        "zpvlfUcwX-Nf",
        "ihc6ZXHci9HM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}